# Scaling Multi-Talker ASR with Speaker-Agnostic Activity Streams

Xiluo He, Alexander Polok, Jesus Villalba, Thomas Thebaud, Matthew Maciejewski

Paper link: \[coming-soon\]

This code is based off of [Target Speaker ASR with Whisper](https://github.com/BUTSpeechFIT/TS-ASR-Whisper).

## 0) Abstract

An increasingly common training paradigm for multi-talker automatic speech recognition (ASR) is to use speaker activity signals to adapt single-speaker ASR models for overlapping speech. Although effective, these systems require running the ASR model once per speaker, resulting in inference costs that scale with the number of speakers and limiting their practicality. In this work, we propose a method that decouples the inference cost of activity-conditioned ASR systems from the number of speakers by converting speaker-specific activity outputs into two speaker-agnostic streams. A central challenge is that na√Øvely merging speaker activities into streams significantly degrades recognition, since pretrained ASR models assume contiguous, single-speaker inputs. To address this, we design new heuristics aimed at preserving conversational continuity and maintaining compatibility with existing systems. We show that our approach is compatible with Diarization-Conditioned Whisper (DiCoW) to greatly reduce runtimes on the AMI and ICSI meeting datasets while retaining competitive performance.

## 1) Install Dependencies
1. Clone the repository: `git clone ...; cd ...`
2. Run `git submodule init; git submodule update`
3. Setup python environment (using conda or virtual environment):
    - Conda: `conda create -n ts_asr_whisper python=3.11`
    - Virtual env: `python -m venv ts_asr_whisper`
4. Activate your environment
5. Install packages: `pip install -r requirements.txt`
6. (Optional) Install flash attention to speed up the model training & inference: `pip install flash-attn==2.7.2.post1` (flash attn requires `torch` to be already installed; hence, cannot be installed through `requirements.txt`)
7. Install `ffmpeg` and `sox` (i.e. using `conda` or `apt`)
8. Change the paths in `configs/local_paths.sh` (variables are explained in the shell script) based on your setup

## 2) Data Preparation
All data preparation, as well as cutset creation, should be saved to `./data`. 

1. To prepare AMI, ICSI, NSF, and Libri2Mix, change the paths in `scripts/data/prepare.sh` and execute it to prepare the data
2. To prepare SparseLibriMix, follow the instructions to create the dataset with the desired overlap conditions in [SparseLibriMix](https://github.com/popcornell/SparseLibriMix/blob/master/create_sparse.sh) and then execute `scripts/data/prepare_sparselibrimix.sh` with updated paths

## 3) Running Experiments
This codebase uses Hydra configuration package. All config yaml files are located in `./configs` and the base configuration file with default values is `configs/base.yaml`

1. Weights: We initialized our all our experiments with a pre-trained CTC Whisper large-v3-turbo: [Download Link](https://nextcloud.fit.vutbr.cz/s/2AHfK2Gj2Jfa6EP). The path to this weight should be specified in `configs/local_paths.sh` and passed into the proper config yaml file as well

2. Conditioning Mask: To use speaker-wise activity conditioning, set the config `use_heat_diar` to false (default). To use HEAT-stream activity conditioning, set `use_heat_diar` to true and specify the config `heat_assignment_method` (`first-available`, `alternating`, `recency-continuity`, or `speaker-continuity`). By default, the HEAT heuristic will be `first-available`.

3. Using external speaker activites: By default, the system will use oracle activity labels to condition the model and to create HEAT-streams from. To use the activities generated by an external diarization system instead, the config `diar_type: 'hard'` needs to be set as well as the config `eval_diar_cutsets`, the path to the diarized cutset. To generate the diarzed cutset using Diarizen, follow the instructions to use inference with [Diarizen](https://huggingface.co/BUT-FIT/diarizen-wavlm-large-s80-md) then create the diarized cutset by executing `./scripts/data/diarize.sh`

To Fine-tune the whole Whisper with target speaker or *stream* amplifiers to perform activity-conditioned ASR, run the example slurm script:
```bash
sbatch ./scripts/training/submit_slurm.sh +train=icassp/heat_conditioning/ami_heat-speaker-continuity
```

Alternatively, to decode and score a trained model, run the example slurm script:
```bash
sbatch ./scripts/training/submit_slurm.sh +decode=ami/best_ami_heat
```

## 4) Description of Different HEAT Heuristics

This codebase creates activity conditioning masks generated from different HEAT heuristics, with performance varying greatly depending on the chosen heuristic. 

To construct HEAT-stream activities for an audio sample, we order the utterances by start times so they can be assigned sequentially. First, both streams are check for "availability" (a stream being "available" for an utterance if, for the entire duration of that utterance, that stream does not contain any other speech activity). If only one stream is available, the utterance is assigned to that stream. If both streams are available, the heuristics determine the stream assignment. 
- `first-available`: assigns utterance to first stream
- `alternating`: assigns utterance to the stream opposite the previous utterance's assignment
- `recency-continuity`: assigns utterance to the most recently active stream
- `speaker-continuity`: assigns utterance to the stream that left off with the current utterance's speaker, if possible. If not, fallback to `recency-continuity` 

| Heuristics | AMI-SDM (cpWER) | ICSI-SDM (cpWER) |
|:-----------:|:-----------:|:-----------:|
| first-available | 32.41 | 40.45 |
| alternating | 22.20 | 25.47 |
| recency-continuity | 20.64 | **24.42** |
| speaker-continuity | **19.71** | 24.94 |
